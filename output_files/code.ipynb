{
  "cells": [
    {
      "metadata": {
        "_uuid": "5120d0c7b9f3f31170ebab5d458b4b4da9232541"
      },
      "cell_type": "markdown",
      "source": "# importing the modules Numpy, Pandas, Matplotlib, Sklearn and  DWT module."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e77c37aff362dbab906c838f2f1a651b429a2c58"
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/mitbih-database\"))\n# annoation, mitbih-database/mitbih_database\n\n\n# Any results you write to the current directory are saved as output.\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import confusion_matrix\n#import xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression , Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n\nfrom sklearn import metrics #for checking the model accuracy\n\nfrom sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n\nfrom sklearn.ensemble import RandomForestClassifier # A combine model of many decision t\n\nfrom sklearn import svm\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\n# Module for discrete wavelet transform\nimport pywt\n\nfrom sklearn.externals import joblib",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b279c4ab8d9552e929253917666fa6e8e06979db"
      },
      "cell_type": "markdown",
      "source": "# Randomly selecting files for training and testing."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7f14c846da9ade7d481608f8bef9ec073c07093"
      },
      "cell_type": "code",
      "source": "lst1=[i for i in range(100,125)]\na=[i+100 for i in [10,20]]\nfor i in a:\n    lst1.remove(i)\nlst2=[i for i in range(200,235)]\na=[i+200 for i in [4,6,11,16,18,24,25,26,27,29]]\nfor i in a:\n    lst2.remove(i)\nlst1+=lst2\nlst=np.array(lst1)\nnp.random.shuffle(lst)\ntrain_lst,test_lst=lst[:43],lst[43:]\nfor i in test_lst:\n    print(i)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d0f2920c6b86ebb6270efa47224167b61dac86a0"
      },
      "cell_type": "markdown",
      "source": "# filtering function:\n**Inputs:**\n\n**x -> df['ML']**\n\n**Outputs:**\n\n**high (arr) -> Bandpass output of the raw (including noise)signal.**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96fe513e494741acb1c28b183845b8e61987b7a8"
      },
      "cell_type": "code",
      "source": "def filtering(x):\n    ##--LOW PASS FILTER\n    x=list(x)\n    low=[0,0]\n    x=12*[0]+x\n    for i,j in zip(range(12,len(x)),range(2,len(x)+2)):\n        low.append(2*low[j-1]-low[j-2]+x[i]-2*x[i-6]+x[i-12])\n    low=low[2:]\n#     print(len(low),len(x))\n    for i,j in enumerate(low):\n        low[i]/=35\n    x=x[12:]\n#     plt.plot(range(1000),x[:1000],c='r',label='MLII')\n#     plt.plot(range(1000),low[:1000],c='b',label='Low pass')\n#     plt.legend()\n#     plt.show()\n\n    ##--HIGH PASS FILTER\n    high=[0]\n    low=32*[0]+low\n    for i,j in zip(range(32,len(low)),range(1,len(low)+1)):\n        high.append(32*low[i-16]-low[i]+low[i-32]-high[j-1])\n    low=low[32:]\n    high=high[1:]\n#     print(len(low),len(high))\n    for i,j in enumerate(high):\n        high[i]/=15\n#     plt.plot(range(1000),high[:1000],c='r',label='IIR Filter')\n#     plt.plot(range(1000),low[:1000],c='b',label='Low pass')\n#     plt.legend()\n#     plt.show()\n\n    return high",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee98e52f3d27fb7dd463868965d919fa1ac40842"
      },
      "cell_type": "markdown",
      "source": "# interpolation function\n**Using the band pass filter output and index of QRS complex, we are downsampling the points between them to 100 points and returning the list of all these points**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7ad295497e530197c2cdbadd0472e2d29c276e0"
      },
      "cell_type": "code",
      "source": "def interpolation(ind,high):\n    total_peaks=[]\n    print(len(ind))\n    for i,j in zip(ind[:-1] , ind[1:]):\n        diff=(j-i)/100\n        val=i\n        arr=[]\n        for k in range(100):\n            val+=diff\n            arr.append(high[round(val)])\n        total_peaks.append(arr)\n#     print(len(total_peaks),len(total_peaks[1]))\n    return total_peaks",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c7bb9afbb08632f397a9f6ecbc678cd3c6ef530b"
      },
      "cell_type": "markdown",
      "source": "# DWT function\n**Using the result of the reduction_testing() we are applying DWT (Discrete Wavelet Transform) on sets of 100 points and storing the coefficients of that in list and returning it.**\n\n**These list of coefficient will act as feature vector for the heart beat.**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95b9c56dcf56b395d5922214125bfd84c6df12a1"
      },
      "cell_type": "code",
      "source": "def wavelet_transform(total_peaks):\n    for i in range(len(total_peaks)):\n        cA,cD= pywt.dwt(total_peaks[i], 'db1')\n        cA.shape=(1,50)\n        cD.shape=(1,50)\n        if i==0:\n            CA=cA.copy()\n            CD=cD.copy()\n        else:\n            CD=np.concatenate((CD,cD))\n            CA=np.concatenate((CA,cA))\n#     print(CA.shape)\n    return CA,CD",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dba75fb0c7fe2bb32fa9f867aa1498c38e4b905b"
      },
      "cell_type": "markdown",
      "source": "# creating_dataframe function:\n**The CA and CD coefficients returned will be converted into pandas dataframe and it is returned.**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ea3c43de8a033470f86ddbbd06f40080a1525c5"
      },
      "cell_type": "code",
      "source": "def creating_dataframe(CA):\n    train_CA=pd.DataFrame(CA,columns=['f{}'.format(i) for i in range(50)])\n    return train_CA",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d65416a550349cb3c9a366855a2f53f96713ef3"
      },
      "cell_type": "markdown",
      "source": "# Creating the dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d77417d5f4704b84d6fd56e65a65ea901a82859c",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "def create_dataset():\n    dataset=pd.DataFrame(columns=['f{}'.format(i) for i in range(50)]+['Sample#']+['Type'])\n    for i in train_lst:\n#         Reading the files\n        print('{} is processing'.format(i))\n        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n        if i in [102,104]:\n            df=df[[\"'sample #'\",\"'V5'\"]]\n            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n        else:\n            df=df[[\"'sample #'\",\"'MLII'\"]]\n            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n        an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n        an=an[['Time','Sample#','Type']]\n#         Creating the Labels ( Category)\n        an['Type'].replace(to_replace=['N', 'P', 'f', 'p', 'Q', '|', '+', 's', 't', '~', 'L', 'R','A', 'a','x', 'J', 'S','V', 'F','e', 'j', 'n', 'E','[',']','!'],value=[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,3,3,4,4,4,4,5,5,5], inplace=True)\n        print(i,an['Type'].unique())\n#         Preprocessing\n        bandpass_output=filtering(df['ML'])\n#         Interpolation\n        total_peaks=interpolation(an['Sample#'],bandpass_output)\n#         Discrete Wavelet Transform\n        CA,CD=wavelet_transform(total_peaks)\n        print(i,CA.shape,len(an['Type']))\n        peak2peak=an['Sample#'].diff()\n        peak2peak=peak2peak[1:]\n#         Creating the Dataframe\n        DS=creating_dataframe(CA)\n        DS=pd.concat([DS , peak2peak] , axis =1)\n        DS=pd.concat([DS,an['Type'][1:]],axis=1)\n#         Adding the dataframe to dataset\n        dataset=pd.concat([dataset,DS],axis=0)\n    \n    dataset.dropna(inplace=True)\n    try:\n        dataset=dataset[dataset['Type']!='\"']\n        dataset=dataset[dataset['Type']!='/']\n    except:\n        pass\n    dataset['Type']=dataset['Type'].astype('int32')\n    \n    return dataset\nds=create_dataset()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "94ee9004804be8507c885af7d6ef06773b2f6752"
      },
      "cell_type": "code",
      "source": "# randomly sampling 20000 datapoints of category 1\nprint(ds['Type'].unique())\nprint(ds['Type'].value_counts())\nds_t1=ds[ds['Type']==1]\nprint(len(ds_t1))\nds_t2=ds[(ds['Type']==2)|(ds['Type']==3)|(ds['Type']==4)|(ds['Type']==5)]\nprint(len(ds_t2))\nprint(len(ds))\nds_t1_sampled=ds_t1.sample(20000)\nds=pd.concat([ds_t1_sampled,ds_t2],axis=0)\nprint(ds['Type'].value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3d0c630b584f07c9a8587f6675416c895de86713"
      },
      "cell_type": "markdown",
      "source": "# Saving dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef2d429c36beb0e82662576cf759b09023e3acf6"
      },
      "cell_type": "code",
      "source": "ds.to_csv('dataset.csv',index=False)\ndf=pd.read_csv('dataset.csv')\ndf.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4187a30771a7de8051fae5a63005284c07ef7bc1"
      },
      "cell_type": "markdown",
      "source": "# Training the dataset using SVM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fb263c539de7492587c37974bb4e6c42b9d14e3"
      },
      "cell_type": "code",
      "source": "print('phase1')\nX_train, X_test, Y_train, Y_test = train_test_split(ds.iloc[:,0:51],ds.iloc[:,51] , test_size = 0.25)\n\nprint('phase2')\nprint(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\nprint(type(X_train))\nprint(X_train.describe())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d1ba36b097ee9896aacb9c16d1824fe7800345f"
      },
      "cell_type": "markdown",
      "source": "# Random Forest"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b2fce501afc04a66cbff2d7df40e9967f2641e3"
      },
      "cell_type": "code",
      "source": "#Random Forest\nclf2 = RandomForestClassifier(n_estimators=100 ,random_state=1)\nclf2.fit(X_train, Y_train)\npre = clf2.predict(X_test)\n\n#Saving model\nfilename = 'random_forest2.sav'\njoblib.dump(clf2, filename)\n\n#Using Current Classfier\nprint('phase4')\npre=clf2.predict(X_test)\n\n#Printing the accuracy score\nprint('phase5')\nprint(accuracy_score(Y_test,pre))\nprint(confusion_matrix(Y_test, pre))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5cd8cf3e8f44a461047a2faa9e5d1d4ca825f5e5"
      },
      "cell_type": "markdown",
      "source": "# Predictions"
    },
    {
      "metadata": {
        "_uuid": "c705934f3a99b4a33cb353afd3dd43e287c3838b"
      },
      "cell_type": "markdown",
      "source": "# Decision Tree"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c84929cb54b26b6333434f45c64c25088942aea"
      },
      "cell_type": "code",
      "source": "#decison tree classifier\nclf3 = DecisionTreeClassifier()\nclf3=clf3.fit(X_train,Y_train)\npre=clf3.predict(X_test)\n\n#Saving model\nfilename = 'Decison_Tree2.sav'\njoblib.dump(clf3, filename)\n\n#Using Current Classfier\nprint('phase4')\npre=clf3.predict(X_test)\n\n#Printing the accuracy score\nprint('phase5')\nprint(accuracy_score(Y_test,pre))\nprint(confusion_matrix(Y_test, pre))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae126cc14a58e7099309b22ac042432c26b7e2bd"
      },
      "cell_type": "code",
      "source": "ds['Type'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8bd2a57814ccd97d421586029fb635ff88f2d569"
      },
      "cell_type": "markdown",
      "source": "# Pan Tompkin's algorithm"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4bb58d0b73835219a083e968521c70035100f80"
      },
      "cell_type": "code",
      "source": "def preprocessing(high):\n    tot=len(high)\n    ##--DERIVATIVE\n    deri=[]\n    high=[0]*2+high+[0]*2\n    for i in range(2,tot+2):\n        deri.append((2*high[i+1]-2*high[i-1]+high[i+2]-high[i-2])/8)\n    high=high[2:-2]\n#     print(len(deri),len(high))\n#     plt.plot(range(l,h),deri[l:h],c='r',label='derivative')\n#     plt.plot(range(l,h),high[l:h],c='b',label='high pass')\n#     plt.legend()\n#     plt.show()\n    ##--SQUARE\n    sq=[]\n    for i in range(len(deri)):\n        sq.append(deri[i]*deri[i])\n#     plt.plot(range(l,h),sq[l:h],c='b',label='squared')\n#     plt.show()\n    ##--MOVING AVERAGE\n    mv=[]\n    n=30\n    sq=[0]*n+sq+[0]*n\n    for i in range(n,len(deri)+n):\n        mv.append(sum(sq[i:i+n])/n)\n    sq=sq[n:-n]\n#     print(len(mv),len(mv))\n#     plt.plot(range(l,h),sq[l:h],c='r',label='squared')\n#     plt.plot(range(l,h),mv[l:h],c='b',label='moving average')\n#     plt.legend()\n#     plt.show()\n    ##--THRESHOLD\n    sps=360\n    spk,npk,thresh,beat_count,prev=0,0,0,0,False\n    thresh1=[]\n    index_arr=[]\n    for j,i in enumerate(mv):\n        if i>thresh:\n            spk=0.125*i+0.875*spk\n        else:\n            npk=0.125*i+0.875*npk\n        thresh=0.75*npk+0.25*spk\n        thresh1.append(200*thresh)\n        if i>thresh and prev==False:\n            beat_count+=1\n            prev=True\n            index_arr.append(j)\n        if i<thresh and prev==True:\n            prev=False\n#     print(len(thresh1))\n#     plt.plot(range(l,h),high[l:h],c='b',label='Bandpass output')\n#     plt.plot(range(l,h),thresh1[l:h],c='r',label='Threshold')\n#     plt.legend()\n#     plt.show()\n    \n    return beat_count,index_arr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9b7f18f401bc9c614475825ef1c12d6d0e7da37a"
      },
      "cell_type": "markdown",
      "source": "# Testing the patients data with the trained model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8e90be484322c497a6e722883593bd24f15d82e"
      },
      "cell_type": "code",
      "source": "print(test_lst)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46693a3b87f50aa1d919f51d123cda2a08635823",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "def testing():\n    dataset=pd.DataFrame(columns=['f{}'.format(i) for i in range(50)]+['Sample#'])\n    for i in test_lst[:]:\n        print('{} is processing'.format(i))\n        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n        if i in [102,104]:\n            df=df[[\"'sample #'\",\"'V5'\"]]\n            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n        else:\n            df=df[[\"'sample #'\",\"'MLII'\"]]\n            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n#         Filtering\n        bandpass_output=filtering(df['ML'])\n        print(df.head())\n#         Preprocessing\n        beat_count,index_arr=preprocessing(bandpass_output)\n#         Interpolation\n        total_peaks=interpolation(index_arr,bandpass_output)\n#         Discrete Wavelet Transform\n        CA,CD=wavelet_transform(total_peaks)\n        temp_df=pd.DataFrame([i-j for i, j in zip(index_arr[1:],index_arr[:-1])] , columns=['Sample#'])\n        DS=creating_dataframe(CA)\n        DS=pd.concat([DS, temp_df] ,axis=1)\n        print(CA.shape)\n    return DS\nX_test=testing()\ntype(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f9700b0551a6512f4acec7eb71002e278f9fb6d"
      },
      "cell_type": "code",
      "source": "y=clf2.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1159b42aa0f5ed82bb9369421e0717922cdde8be"
      },
      "cell_type": "code",
      "source": "uni,cnt=np.unique(y,return_counts=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "101cfdd50041943177d102f5c8c44bd3ab470bc0"
      },
      "cell_type": "code",
      "source": "uni",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5be133ae80854cadfa2978e024848645830e0a8c"
      },
      "cell_type": "code",
      "source": "cnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe3b0fea90d6e5e4bccc939cbe55ef27d39bacd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}